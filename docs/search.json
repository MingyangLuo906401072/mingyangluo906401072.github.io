[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Mingyang Luo",
    "section": "",
    "text": "Welcome to my blogs"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Hellow ML",
    "section": "",
    "text": "Dry Beans Anaysis\n\n\n\n\n\n\n\nClassification\n\n\nClustering\n\n\nAnomaly Detection\n\n\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\nMingyang Luo\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nClassification\n\n\nAnomaly Detection\n\n\nClustering\n\n\n\n\n\n\n\n\n\n\n\nNov 5, 2023\n\n\nMingyang Luo\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Dry Beans Anaysis",
    "section": "",
    "text": "This is a post with executable code.\n\nimport pandas as pd\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import accuracy_score, classification_report, roc_curve, auc, roc_auc_score\nimport matplotlib.pyplot as plt\nimport matplotlib\nimport numpy as np\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\nimport scipy.cluster.hierarchy as sch\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import recall_score\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import ConfusionMatrixDisplay\nfrom sklearn.inspection import DecisionBoundaryDisplay\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import label_binarize\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\n\nexcel_file_path = \"DryBeanDataset/Dry_Bean_Dataset.xlsx\"\ndf = pd.read_excel(excel_file_path)\ndf\n\n\n\n\n\n\n\n\nArea\nPerimeter\nMajorAxisLength\nMinorAxisLength\nAspectRation\nEccentricity\nConvexArea\nEquivDiameter\nExtent\nSolidity\nroundness\nCompactness\nShapeFactor1\nShapeFactor2\nShapeFactor3\nShapeFactor4\nClass\n\n\n\n\n0\n28395\n610.291\n208.178117\n173.888747\n1.197191\n0.549812\n28715\n190.141097\n0.763923\n0.988856\n0.958027\n0.913358\n0.007332\n0.003147\n0.834222\n0.998724\nSEKER\n\n\n1\n28734\n638.018\n200.524796\n182.734419\n1.097356\n0.411785\n29172\n191.272750\n0.783968\n0.984986\n0.887034\n0.953861\n0.006979\n0.003564\n0.909851\n0.998430\nSEKER\n\n\n2\n29380\n624.110\n212.826130\n175.931143\n1.209713\n0.562727\n29690\n193.410904\n0.778113\n0.989559\n0.947849\n0.908774\n0.007244\n0.003048\n0.825871\n0.999066\nSEKER\n\n\n3\n30008\n645.884\n210.557999\n182.516516\n1.153638\n0.498616\n30724\n195.467062\n0.782681\n0.976696\n0.903936\n0.928329\n0.007017\n0.003215\n0.861794\n0.994199\nSEKER\n\n\n4\n30140\n620.134\n201.847882\n190.279279\n1.060798\n0.333680\n30417\n195.896503\n0.773098\n0.990893\n0.984877\n0.970516\n0.006697\n0.003665\n0.941900\n0.999166\nSEKER\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n13606\n42097\n759.696\n288.721612\n185.944705\n1.552728\n0.765002\n42508\n231.515799\n0.714574\n0.990331\n0.916603\n0.801865\n0.006858\n0.001749\n0.642988\n0.998385\nDERMASON\n\n\n13607\n42101\n757.499\n281.576392\n190.713136\n1.476439\n0.735702\n42494\n231.526798\n0.799943\n0.990752\n0.922015\n0.822252\n0.006688\n0.001886\n0.676099\n0.998219\nDERMASON\n\n\n13608\n42139\n759.321\n281.539928\n191.187979\n1.472582\n0.734065\n42569\n231.631261\n0.729932\n0.989899\n0.918424\n0.822730\n0.006681\n0.001888\n0.676884\n0.996767\nDERMASON\n\n\n13609\n42147\n763.779\n283.382636\n190.275731\n1.489326\n0.741055\n42667\n231.653248\n0.705389\n0.987813\n0.907906\n0.817457\n0.006724\n0.001852\n0.668237\n0.995222\nDERMASON\n\n\n13610\n42159\n772.237\n295.142741\n182.204716\n1.619841\n0.786693\n42600\n231.686223\n0.788962\n0.989648\n0.888380\n0.784997\n0.007001\n0.001640\n0.616221\n0.998180\nDERMASON\n\n\n\n\n13611 rows × 17 columns\n\n\n\n\nnumeric_df = df.select_dtypes(include=['number'])\ncols = numeric_df.columns\nscaler = StandardScaler()\nnumeric_df = scaler.fit_transform(numeric_df)\npca = PCA(n_components=2)\ndf_pca = pca.fit_transform(numeric_df)\nnormalized_df = pd.DataFrame(numeric_df, columns=cols)\n\nplt.figure(figsize=(23, 6))  \npd.plotting.parallel_coordinates(normalized_df.join(df.Class), class_column='Class', colormap='hsv') \nplt.title('Standardized Parallel Coordinates Plot')\nplt.ylabel('Values')\nplt.show()\n\n\n\n\n\nkmeans = KMeans(n_clusters=7, random_state=42)\ndf['Cluster'] = kmeans.fit_predict(df_pca)\nlabels = kmeans.labels_\n\ncluster_centers = kmeans.cluster_centers_\n\ndistances = []\nfor i, label in enumerate(kmeans.labels_):\n    center = cluster_centers[label]\n    point = df_pca[i]\n    distance = np.linalg.norm(point - center)  # Euclidean distance\n    distances.append(distance)\n\nthreshold = np.percentile(distances, 99)  \nanomalies = df_pca[np.array(distances) &gt; threshold]\n\nplt.figure(figsize=(8, 6))\nplt.scatter(df_pca[:, 0], df_pca[:, 1], c=labels, cmap='viridis', marker='o', alpha=0.6)\nplt.scatter(cluster_centers[:, 0], cluster_centers[:, 1], s=100, c='cyan', marker='o', label='Cluster Centers')\nplt.xlabel(f'Principal Component 1 (Explained Variance: {pca.explained_variance_ratio_[0]:.3f}')\nplt.ylabel(f'Principal Component 2 (Explained Variance: {pca.explained_variance_ratio_[1]:.3f}')\nplt.title('Clustering of Dry Beans using KMeans with 7 clusters')\nplt.scatter(anomalies[:, 0], anomalies[:, 1], c='red', marker='x', s=100, label='Anomalies')\nplt.legend()\nplt.show()\n\n\n\n\n\nX1 = df_pca\ny1 = df['Class']\nlabel_encoder = LabelEncoder()\ny1 = label_encoder.fit_transform(y1)\nfeature_1, feature_2 = np.meshgrid(\n    np.linspace(X1[:, 0].min(), X1[:, 0].max()),\n    np.linspace(X1[:, 1].min(), X1[:, 1].max())\n)\ngrid = np.vstack([feature_1.ravel(), feature_2.ravel()]).T\ntree = DecisionTreeClassifier().fit(X1, y1)\ny_pred1 = tree.predict(grid)\ny_pred1 = y_pred1.reshape(feature_1.shape)\ndisplay = DecisionBoundaryDisplay(xx0=feature_1, xx1=feature_2, response=y_pred1)\ndisplay.plot()\nplt.scatter(X1[:, 0], X1[:, 1], c=y1, edgecolor=\"k\", s=10)\nplt.show()\n\n\n\n\n\ncluster_data = pd.DataFrame({'Cluster': df['Cluster'], 'Class': df['Class']})  \ncluster_summary = cluster_data.groupby('Cluster')['Class'].value_counts().unstack().fillna(0)\nprint(cluster_summary)\n\nClass    BARBUNYA  BOMBAY    CALI  DERMASON   HOROZ   SEKER    SIRA\nCluster                                                            \n0             9.0     0.0     2.0     116.0     0.0  1869.0    29.0\n1            12.0     0.0    23.0      12.0  1814.0     1.0    72.0\n2            98.0     0.0    13.0     457.0    52.0    77.0  2280.0\n3             1.0   520.0     0.0       0.0     0.0     0.0     0.0\n4             0.0     0.0     0.0    2961.0     3.0    77.0   249.0\n5           824.0     2.0   347.0       0.0     0.0     3.0     1.0\n6           378.0     0.0  1245.0       0.0    59.0     0.0     5.0\n\n\n\nX = numeric_df \ny = df['Class']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nclf = DecisionTreeClassifier(max_depth=8, random_state=42)\nclf.fit(X_train, y_train)\n\ny_scores = clf.predict_proba(X_test)\ny_pred = clf.predict(X_test)\n\ncm = confusion_matrix(y_test, y_pred, labels=clf.classes_)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=clf.classes_)\ndisp.plot(cmap='Blues', values_format='d')\nplt.show()\n\n\n\n\n\ny_bin = label_binarize(y_test, classes=clf.classes_)\n\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\n\nfor i in range(len(clf.classes_)):\n    fpr[i], tpr[i], _ = roc_curve(y_bin[:, i], y_scores[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# Plot ROC curves\nplt.figure(figsize=(8, 6))\n\nfor i in range(len(clf.classes_)):\n    plt.plot(fpr[i], tpr[i], label=f'ROC curve (area = {roc_auc[i]:.2f}) for class {clf.classes_[i]}')\n\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic (ROC) Curve for Multiclass Classification')\nplt.legend(loc=\"lower right\")\nplt.show()\n\n\n\n\n\ntrain_sizes, train_scores, test_scores = learning_curve(clf, X_train, y_train, train_sizes=np.linspace(0.1, 1.0, 10), cv=5, scoring='accuracy')\n\ntrain_scores_mean = np.mean(train_scores, axis=1)\ntrain_scores_std = np.std(train_scores, axis=1)\ntest_scores_mean = np.mean(test_scores, axis=1)\ntest_scores_std = np.std(test_scores, axis=1)\n\nplt.figure()\nplt.title(\"Learning Curve\")\nplt.xlabel(\"Training examples\")\nplt.ylabel(\"Accuracy\")\n\nplt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\nplt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n\nplt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\nplt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n\nplt.legend()\nplt.show()\n\n\n\n\n\nfrom IPython.display import Image\nimport pydot\nfrom sklearn.tree import export_graphviz\nimport graphviz\n\ndata=export_graphviz(\n    clf,\n    feature_names=df.drop(columns=['Class', 'Cluster']).columns,\n    class_names=clf.classes_,\n    rounded=True,\n    filled=True,\n    max_depth=4,\n)\n\ngraph = pydot.graph_from_dot_data(data)\nImage(graph[0].create_png())\n\n# graph = graphviz.Source(data)\n# graph.render(\"decision_tree\")\n\n\n\n\n\nroc_auc = roc_auc_score(y_test, y_scores, multi_class='ovo')  \nprint(f'ROC AUC Score: {roc_auc:.2f}')\n\nROC AUC Score: 0.98\n\n\n\nscores = cross_val_score(clf, X, y, cv=5, scoring='accuracy')\nmean_score = scores.mean()\nstd_score = scores.std()\nprint(f'Standard Error Score: {std_score:.2f}')\n\nStandard Error Score: 0.18\n\n\n\n# recall = recall_score(y_test, y_pred, average=None)\nrecall = recall_score(y_test, y_pred, average='macro')\nprint(f'Recall Score: {recall:.2f}')\n\nRecall Score: 0.91\n\n\n\nX_train1, X_test1, y_train1, y_test1 = train_test_split(X, y, test_size=0.2, random_state=42)\n\nclf1 = RandomForestClassifier(n_estimators=20, max_depth=8, random_state=42)\nclf1.fit(X_train1, y_train1)\n\ny_scores1 = clf1.predict_proba(X_test1)\n\nfpr1 = dict()\ntpr1 = dict()\nroc_auc1 = dict()\n\nfor i in range(len(clf1.classes_)):\n    fpr1[i], tpr1[i], _ = roc_curve((y_test1 == clf1.classes_[i]).astype(int), y_scores1[:, i])\n    roc_auc1[i] = auc(fpr1[i], tpr1[i])\n\nplt.figure(figsize=(8, 6))\n\nfor i in range(len(clf1.classes_)):\n    plt.plot(fpr1[i], tpr1[i], label=f'ROC curve (area = {roc_auc1[i]:.2f}) for class {clf1.classes_[i]}')\n\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic (ROC) Curve for Multiclass Classification')\nplt.legend(loc=\"lower right\")\nplt.show()\n\n\n\n\n\ntrain_sizes1, train_scores1, test_scores1 = learning_curve(clf1, X_train1, y_train1, train_sizes=np.linspace(0.1, 1.0, 10), cv=5, scoring='accuracy')\n\ntrain_scores_mean1 = np.mean(train_scores1, axis=1)\ntrain_scores_std1 = np.std(train_scores1, axis=1)\ntest_scores_mean1 = np.mean(test_scores1, axis=1)\ntest_scores_std1 = np.std(test_scores1, axis=1)\n\nplt.figure()\nplt.title(\"Learning Curve\")\nplt.xlabel(\"Training examples\")\nplt.ylabel(\"Accuracy\")\n\nplt.plot(train_sizes1, train_scores_mean1, 'o-', color=\"r\", label=\"Training score\")\nplt.plot(train_sizes1, test_scores_mean1, 'o-', color=\"g\", label=\"Cross-validation score\")\n\nplt.fill_between(train_sizes1, train_scores_mean1 - train_scores_std1, train_scores_mean1 + train_scores_std1, alpha=0.1, color=\"r\")\nplt.fill_between(train_sizes1, test_scores_mean1 - test_scores_std1, test_scores_mean1 + test_scores_std1, alpha=0.1, color=\"g\")\n\nplt.legend()\nplt.show()\n\n\n\n\n\ny_pred1 = clf1.predict(X_test1)\ncm1 = confusion_matrix(y_test1, y_pred1, labels=clf1.classes_)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm1, display_labels=clf1.classes_)\ndisp.plot(cmap='Purples', values_format='d')\nplt.show()\n\n\n\n\n\nscores = cross_val_score(clf, X, y, cv=5, scoring='accuracy')\nmean_score = scores.mean()\nstd_score = scores.std()\nprint(f'Standard Error Score: {std_score:.2f}')\n\nStandard Error Score: 0.18\n\n\n\nrecall = recall_score(y_test, y_pred, average='macro')\nprint(f'Recall Score: {recall:.2f}')\n\nRecall Score: 0.91\n\n\n\nroc_auc = roc_auc_score(y_test, y_scores, multi_class='ovo')  \nprint(f'ROC AUC Score: {roc_auc:.2f}')\n\nROC AUC Score: 0.98\n\n\n\nX_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, test_size=0.2, random_state=42)\n\nclf2 = SVC(probability=True, C=0.2, random_state=42)\nclf2.fit(X_train2, y_train2)\n\ny_scores2 = clf2.predict_proba(X_test2)\n\nfpr2 = dict()\ntpr2 = dict()\nroc_auc2 = dict()\n\nfor i in range(len(clf2.classes_)):\n    fpr2[i], tpr2[i], _ = roc_curve((y_test2 == clf2.classes_[i]).astype(int), y_scores2[:, i])\n    roc_auc2[i] = auc(fpr2[i], tpr2[i])\n\nplt.figure(figsize=(8, 6))\n\nfor i in range(len(clf2.classes_)):\n    plt.plot(fpr2[i], tpr2[i], label=f'ROC curve (area = {roc_auc2[i]:.2f}) for class {clf2.classes_[i]}')\n\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic (ROC) Curve for Multiclass Classification')\nplt.legend(loc=\"lower right\")\nplt.show()"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  }
]