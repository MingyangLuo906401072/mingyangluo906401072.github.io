[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Mingyang Luo",
    "section": "",
    "text": "Welcome to my blogs"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Hellow ML",
    "section": "",
    "text": "Earthquake Analysis\n\n\n\n\n\n\n\nRegression\n\n\n\n\n\n\n\n\n\n\n\nNov 18, 2023\n\n\nMingyang Luo\n\n\n\n\n\n\n  \n\n\n\n\nDry Beans Anaysis\n\n\n\n\n\n\n\nClassification\n\n\nClustering\n\n\nAnomaly Detection\n\n\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\nMingyang Luo\n\n\n\n\n\n\n  \n\n\n\n\nDisease Analysis\n\n\n\n\n\n\n\nClassification\n\n\nAnomaly Detection\n\n\nClustering\n\n\n\n\n\n\n\n\n\n\n\nNov 5, 2023\n\n\nMingyang Luo\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Dry Beans Anaysis",
    "section": "",
    "text": "This is a post with executable code.\n\nimport pandas as pd\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import accuracy_score, classification_report, roc_curve, auc, roc_auc_score\nimport matplotlib.pyplot as plt\nimport matplotlib\nimport numpy as np\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\nimport scipy.cluster.hierarchy as sch\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import recall_score\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import ConfusionMatrixDisplay\nfrom sklearn.inspection import DecisionBoundaryDisplay\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import label_binarize\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\n\nexcel_file_path = \"DryBeanDataset/Dry_Bean_Dataset.xlsx\"\ndf = pd.read_excel(excel_file_path)\ndf\n\n\n\n\n\n\n\n\nArea\nPerimeter\nMajorAxisLength\nMinorAxisLength\nAspectRation\nEccentricity\nConvexArea\nEquivDiameter\nExtent\nSolidity\nroundness\nCompactness\nShapeFactor1\nShapeFactor2\nShapeFactor3\nShapeFactor4\nClass\n\n\n\n\n0\n28395\n610.291\n208.178117\n173.888747\n1.197191\n0.549812\n28715\n190.141097\n0.763923\n0.988856\n0.958027\n0.913358\n0.007332\n0.003147\n0.834222\n0.998724\nSEKER\n\n\n1\n28734\n638.018\n200.524796\n182.734419\n1.097356\n0.411785\n29172\n191.272750\n0.783968\n0.984986\n0.887034\n0.953861\n0.006979\n0.003564\n0.909851\n0.998430\nSEKER\n\n\n2\n29380\n624.110\n212.826130\n175.931143\n1.209713\n0.562727\n29690\n193.410904\n0.778113\n0.989559\n0.947849\n0.908774\n0.007244\n0.003048\n0.825871\n0.999066\nSEKER\n\n\n3\n30008\n645.884\n210.557999\n182.516516\n1.153638\n0.498616\n30724\n195.467062\n0.782681\n0.976696\n0.903936\n0.928329\n0.007017\n0.003215\n0.861794\n0.994199\nSEKER\n\n\n4\n30140\n620.134\n201.847882\n190.279279\n1.060798\n0.333680\n30417\n195.896503\n0.773098\n0.990893\n0.984877\n0.970516\n0.006697\n0.003665\n0.941900\n0.999166\nSEKER\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n13606\n42097\n759.696\n288.721612\n185.944705\n1.552728\n0.765002\n42508\n231.515799\n0.714574\n0.990331\n0.916603\n0.801865\n0.006858\n0.001749\n0.642988\n0.998385\nDERMASON\n\n\n13607\n42101\n757.499\n281.576392\n190.713136\n1.476439\n0.735702\n42494\n231.526798\n0.799943\n0.990752\n0.922015\n0.822252\n0.006688\n0.001886\n0.676099\n0.998219\nDERMASON\n\n\n13608\n42139\n759.321\n281.539928\n191.187979\n1.472582\n0.734065\n42569\n231.631261\n0.729932\n0.989899\n0.918424\n0.822730\n0.006681\n0.001888\n0.676884\n0.996767\nDERMASON\n\n\n13609\n42147\n763.779\n283.382636\n190.275731\n1.489326\n0.741055\n42667\n231.653248\n0.705389\n0.987813\n0.907906\n0.817457\n0.006724\n0.001852\n0.668237\n0.995222\nDERMASON\n\n\n13610\n42159\n772.237\n295.142741\n182.204716\n1.619841\n0.786693\n42600\n231.686223\n0.788962\n0.989648\n0.888380\n0.784997\n0.007001\n0.001640\n0.616221\n0.998180\nDERMASON\n\n\n\n\n13611 rows × 17 columns\n\n\n\n\nnumeric_df = df.select_dtypes(include=['number'])\ncols = numeric_df.columns\nscaler = StandardScaler()\nnumeric_df = scaler.fit_transform(numeric_df)\npca = PCA(n_components=2)\ndf_pca = pca.fit_transform(numeric_df)\nnormalized_df = pd.DataFrame(numeric_df, columns=cols)\n\nplt.figure(figsize=(23, 6))  \npd.plotting.parallel_coordinates(normalized_df.join(df.Class), class_column='Class', colormap='hsv') \nplt.title('Standardized Parallel Coordinates Plot')\nplt.ylabel('Values')\nplt.show()\n\n\n\n\n\nkmeans = KMeans(n_clusters=7, random_state=42)\ndf['Cluster'] = kmeans.fit_predict(df_pca)\nlabels = kmeans.labels_\n\ncluster_centers = kmeans.cluster_centers_\n\ndistances = []\nfor i, label in enumerate(kmeans.labels_):\n    center = cluster_centers[label]\n    point = df_pca[i]\n    distance = np.linalg.norm(point - center)  # Euclidean distance\n    distances.append(distance)\n\nthreshold = np.percentile(distances, 99)  \nanomalies = df_pca[np.array(distances) &gt; threshold]\n\nplt.figure(figsize=(8, 6))\nplt.scatter(df_pca[:, 0], df_pca[:, 1], c=labels, cmap='viridis', marker='o', alpha=0.6)\nplt.scatter(cluster_centers[:, 0], cluster_centers[:, 1], s=100, c='cyan', marker='o', label='Cluster Centers')\nplt.xlabel(f'Principal Component 1 (Explained Variance: {pca.explained_variance_ratio_[0]:.3f}')\nplt.ylabel(f'Principal Component 2 (Explained Variance: {pca.explained_variance_ratio_[1]:.3f}')\nplt.title('Clustering of Dry Beans using KMeans with 7 clusters')\nplt.scatter(anomalies[:, 0], anomalies[:, 1], c='red', marker='x', s=100, label='Anomalies')\nplt.legend()\nplt.show()\n\n\n\n\n\nX1 = df_pca\ny1 = df['Class']\nlabel_encoder = LabelEncoder()\ny1 = label_encoder.fit_transform(y1)\nfeature_1, feature_2 = np.meshgrid(\n    np.linspace(X1[:, 0].min(), X1[:, 0].max()),\n    np.linspace(X1[:, 1].min(), X1[:, 1].max())\n)\ngrid = np.vstack([feature_1.ravel(), feature_2.ravel()]).T\ntree = DecisionTreeClassifier().fit(X1, y1)\ny_pred1 = tree.predict(grid)\ny_pred1 = y_pred1.reshape(feature_1.shape)\ndisplay = DecisionBoundaryDisplay(xx0=feature_1, xx1=feature_2, response=y_pred1)\ndisplay.plot()\nplt.scatter(X1[:, 0], X1[:, 1], c=y1, edgecolor=\"k\", s=10)\nplt.show()\n\n\n\n\n\ncluster_data = pd.DataFrame({'Cluster': df['Cluster'], 'Class': df['Class']})  \ncluster_summary = cluster_data.groupby('Cluster')['Class'].value_counts().unstack().fillna(0)\nprint(cluster_summary)\n\nClass    BARBUNYA  BOMBAY    CALI  DERMASON   HOROZ   SEKER    SIRA\nCluster                                                            \n0             9.0     0.0     2.0     116.0     0.0  1869.0    29.0\n1            12.0     0.0    23.0      12.0  1814.0     1.0    72.0\n2            98.0     0.0    13.0     457.0    52.0    77.0  2280.0\n3             1.0   520.0     0.0       0.0     0.0     0.0     0.0\n4             0.0     0.0     0.0    2961.0     3.0    77.0   249.0\n5           824.0     2.0   347.0       0.0     0.0     3.0     1.0\n6           378.0     0.0  1245.0       0.0    59.0     0.0     5.0\n\n\n\nX = numeric_df \ny = df['Class']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nclf = DecisionTreeClassifier(max_depth=8, random_state=42)\nclf.fit(X_train, y_train)\n\ny_scores = clf.predict_proba(X_test)\ny_pred = clf.predict(X_test)\n\ncm = confusion_matrix(y_test, y_pred, labels=clf.classes_)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=clf.classes_)\ndisp.plot(cmap='Blues', values_format='d')\nplt.show()\n\n\n\n\n\ny_bin = label_binarize(y_test, classes=clf.classes_)\n\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\n\nfor i in range(len(clf.classes_)):\n    fpr[i], tpr[i], _ = roc_curve(y_bin[:, i], y_scores[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# Plot ROC curves\nplt.figure(figsize=(8, 6))\n\nfor i in range(len(clf.classes_)):\n    plt.plot(fpr[i], tpr[i], label=f'ROC curve (area = {roc_auc[i]:.2f}) for class {clf.classes_[i]}')\n\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic (ROC) Curve for Multiclass Classification')\nplt.legend(loc=\"lower right\")\nplt.show()\n\n\n\n\n\ntrain_sizes, train_scores, test_scores = learning_curve(clf, X_train, y_train, train_sizes=np.linspace(0.1, 1.0, 10), cv=5, scoring='accuracy')\n\ntrain_scores_mean = np.mean(train_scores, axis=1)\ntrain_scores_std = np.std(train_scores, axis=1)\ntest_scores_mean = np.mean(test_scores, axis=1)\ntest_scores_std = np.std(test_scores, axis=1)\n\nplt.figure()\nplt.title(\"Learning Curve\")\nplt.xlabel(\"Training examples\")\nplt.ylabel(\"Accuracy\")\n\nplt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\nplt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n\nplt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\nplt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n\nplt.legend()\nplt.show()\n\n\n\n\n\nfrom IPython.display import Image\nimport pydot\nfrom sklearn.tree import export_graphviz\nimport graphviz\n\ndata=export_graphviz(\n    clf,\n    feature_names=df.drop(columns=['Class', 'Cluster']).columns,\n    class_names=clf.classes_,\n    rounded=True,\n    filled=True,\n    max_depth=4,\n)\n\ngraph = pydot.graph_from_dot_data(data)\nImage(graph[0].create_png())\n\n# graph = graphviz.Source(data)\n# graph.render(\"decision_tree\")\n\n\n\n\n\nroc_auc = roc_auc_score(y_test, y_scores, multi_class='ovo')  \nprint(f'ROC AUC Score: {roc_auc:.2f}')\n\nROC AUC Score: 0.98\n\n\n\nscores = cross_val_score(clf, X, y, cv=5, scoring='accuracy')\nmean_score = scores.mean()\nstd_score = scores.std()\nprint(f'Standard Error Score: {std_score:.2f}')\n\nStandard Error Score: 0.18\n\n\n\n# recall = recall_score(y_test, y_pred, average=None)\nrecall = recall_score(y_test, y_pred, average='macro')\nprint(f'Recall Score: {recall:.2f}')\n\nRecall Score: 0.91\n\n\n\nX_train1, X_test1, y_train1, y_test1 = train_test_split(X, y, test_size=0.2, random_state=42)\n\nclf1 = RandomForestClassifier(n_estimators=20, max_depth=8, random_state=42)\nclf1.fit(X_train1, y_train1)\n\ny_scores1 = clf1.predict_proba(X_test1)\n\nfpr1 = dict()\ntpr1 = dict()\nroc_auc1 = dict()\n\nfor i in range(len(clf1.classes_)):\n    fpr1[i], tpr1[i], _ = roc_curve((y_test1 == clf1.classes_[i]).astype(int), y_scores1[:, i])\n    roc_auc1[i] = auc(fpr1[i], tpr1[i])\n\nplt.figure(figsize=(8, 6))\n\nfor i in range(len(clf1.classes_)):\n    plt.plot(fpr1[i], tpr1[i], label=f'ROC curve (area = {roc_auc1[i]:.2f}) for class {clf1.classes_[i]}')\n\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic (ROC) Curve for Multiclass Classification')\nplt.legend(loc=\"lower right\")\nplt.show()\n\n\n\n\n\ntrain_sizes1, train_scores1, test_scores1 = learning_curve(clf1, X_train1, y_train1, train_sizes=np.linspace(0.1, 1.0, 10), cv=5, scoring='accuracy')\n\ntrain_scores_mean1 = np.mean(train_scores1, axis=1)\ntrain_scores_std1 = np.std(train_scores1, axis=1)\ntest_scores_mean1 = np.mean(test_scores1, axis=1)\ntest_scores_std1 = np.std(test_scores1, axis=1)\n\nplt.figure()\nplt.title(\"Learning Curve\")\nplt.xlabel(\"Training examples\")\nplt.ylabel(\"Accuracy\")\n\nplt.plot(train_sizes1, train_scores_mean1, 'o-', color=\"r\", label=\"Training score\")\nplt.plot(train_sizes1, test_scores_mean1, 'o-', color=\"g\", label=\"Cross-validation score\")\n\nplt.fill_between(train_sizes1, train_scores_mean1 - train_scores_std1, train_scores_mean1 + train_scores_std1, alpha=0.1, color=\"r\")\nplt.fill_between(train_sizes1, test_scores_mean1 - test_scores_std1, test_scores_mean1 + test_scores_std1, alpha=0.1, color=\"g\")\n\nplt.legend()\nplt.show()\n\n\n\n\n\ny_pred1 = clf1.predict(X_test1)\ncm1 = confusion_matrix(y_test1, y_pred1, labels=clf1.classes_)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm1, display_labels=clf1.classes_)\ndisp.plot(cmap='Purples', values_format='d')\nplt.show()\n\n\n\n\n\nscores = cross_val_score(clf, X, y, cv=5, scoring='accuracy')\nmean_score = scores.mean()\nstd_score = scores.std()\nprint(f'Standard Error Score: {std_score:.2f}')\n\nStandard Error Score: 0.18\n\n\n\nrecall = recall_score(y_test, y_pred, average='macro')\nprint(f'Recall Score: {recall:.2f}')\n\nRecall Score: 0.91\n\n\n\nroc_auc = roc_auc_score(y_test, y_scores, multi_class='ovo')  \nprint(f'ROC AUC Score: {roc_auc:.2f}')\n\nROC AUC Score: 0.98\n\n\n\nX_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, test_size=0.2, random_state=42)\n\nclf2 = SVC(probability=True, C=0.2, random_state=42)\nclf2.fit(X_train2, y_train2)\n\ny_scores2 = clf2.predict_proba(X_test2)\n\nfpr2 = dict()\ntpr2 = dict()\nroc_auc2 = dict()\n\nfor i in range(len(clf2.classes_)):\n    fpr2[i], tpr2[i], _ = roc_curve((y_test2 == clf2.classes_[i]).astype(int), y_scores2[:, i])\n    roc_auc2[i] = auc(fpr2[i], tpr2[i])\n\nplt.figure(figsize=(8, 6))\n\nfor i in range(len(clf2.classes_)):\n    plt.plot(fpr2[i], tpr2[i], label=f'ROC curve (area = {roc_auc2[i]:.2f}) for class {clf2.classes_[i]}')\n\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic (ROC) Curve for Multiclass Classification')\nplt.legend(loc=\"lower right\")\nplt.show()"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/earthquakes/index.html",
    "href": "posts/earthquakes/index.html",
    "title": "Earthquake Analysis",
    "section": "",
    "text": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.multioutput import MultiOutputRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.linear_model import Lasso\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\n\ncsv_file_path = \"earthquakes.csv\"\ndf = pd.read_csv(csv_file_path)\ndf\n\n\n\n\n\n\n\n\nid\nimpact.gap\nimpact.magnitude\nimpact.significance\nlocation.depth\nlocation.distance\nlocation.full\nlocation.latitude\nlocation.longitude\nlocation.name\ntime.day\ntime.epoch\ntime.full\ntime.hour\ntime.minute\ntime.month\ntime.second\ntime.year\n\n\n\n\n0\nnc72666881\n122.00\n1.43\n31\n15.12\n0.10340\n13km E of Livermore, California\n37.672333\n-121.619000\nCalifornia\n27\n1469593183550\n2016-07-27 00:19:43\n0\n19\n7\n43\n2016\n\n\n1\nus20006i0y\n30.00\n4.90\n371\n97.07\n1.43900\n58km WNW of Pakokku, Burma\n21.514600\n94.572100\nBurma\n27\n1469593228220\n2016-07-27 00:20:28\n0\n20\n7\n28\n2016\n\n\n2\nnc72666891\n249.00\n0.06\n0\n4.39\n0.02743\n12km SE of Mammoth Lakes, California\n37.576500\n-118.859167\nCalifornia\n27\n1469593897150\n2016-07-27 00:31:37\n0\n31\n7\n37\n2016\n\n\n3\nnc72666896\n122.00\n0.40\n2\n1.09\n0.02699\n6km SSW of Mammoth Lakes, California\n37.595833\n-118.994833\nCalifornia\n27\n1469594144150\n2016-07-27 00:35:44\n0\n35\n7\n44\n2016\n\n\n4\nnn00553447\n113.61\n0.30\n1\n7.60\n0.06300\n16km SSE of Mogul, Nevada\n39.377500\n-119.845000\nNevada\n27\n1469594519667\n2016-07-27 00:41:59\n0\n41\n7\n59\n2016\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n8389\nnc72685246\n47.00\n2.42\n90\n4.85\n0.06167\n22km ENE of Soledad, California\n36.515499\n-121.099831\nCalifornia\n25\n1472181541970\n2016-08-25 23:19:01\n23\n19\n8\n1\n2016\n\n\n8390\nak13879193\n0.00\n1.40\n30\n50.00\n0.00000\n5km ESE of Big Lake, Alaska\n61.498400\n-149.862700\nAlaska\n25\n1472181558000\n2016-08-25 23:19:18\n23\n19\n8\n18\n2016\n\n\n8391\nnc72685251\n165.00\n1.06\n17\n1.73\n0.02042\n6km WNW of The Geysers, California\n38.805000\n-122.821503\nCalifornia\n25\n1472182205600\n2016-08-25 23:30:05\n23\n30\n8\n5\n2016\n\n\n8392\nci37672328\n103.00\n1.55\n37\n29.25\n0.06980\n6km NNW of Chatsworth, CA\n34.308000\n-118.635333\nCalifornia\n25\n1472182571880\n2016-08-25 23:36:11\n23\n36\n8\n11\n2016\n\n\n8393\nci37672360\n99.00\n0.89\n12\n8.29\n0.02562\n14km NE of Yucaipa, CA\n34.119167\n-116.933667\nCalifornia\n25\n1472183881830\n2016-08-25 23:58:01\n23\n58\n8\n1\n2016\n\n\n\n\n8394 rows × 18 columns\n\n\n\n\nnumeric = df.select_dtypes(include=['number'])\nscaler = StandardScaler()\nnumeric1 = scaler.fit_transform(numeric)\nnumeric_df = pd.DataFrame(numeric1)\nnumeric_df.columns = numeric.columns\nnumeric_df.columns\n\nIndex(['impact.gap', 'impact.magnitude', 'impact.significance',\n       'location.depth', 'location.distance', 'location.latitude',\n       'location.longitude', 'time.day', 'time.epoch', 'time.hour',\n       'time.minute', 'time.month', 'time.second', 'time.year'],\n      dtype='object')\n\n\n\nX = numeric_df[['location.depth', 'location.latitude','location.longitude', 'time.epoch', 'impact.gap']]\ny = numeric_df[['impact.magnitude', 'time.month', 'time.day']]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\npoly_model = MultiOutputRegressor(make_pipeline(PolynomialFeatures(2, include_bias=False), Lasso(alpha=0.4)))\npoly_model.fit(X_train, y_train)\n\npoly_predictions = poly_model.predict(X_test)\nmse = mean_squared_error(y_test, poly_predictions)\nprint(f\"Mean Squared Error: {mse}\")\n\nMean Squared Error: 0.6435738280241988\n\n\n\ntrain_sizes, train_scores, test_scores = learning_curve(poly_model, X, y, cv=5, scoring='neg_mean_squared_error')\n\ntrain_scores_mean = -train_scores.mean(axis=1)\ntest_scores_mean = -test_scores.mean(axis=1)\n\nplt.figure()\nplt.title(\"Learning Curve\")\nplt.xlabel(\"Training examples\")\nplt.ylabel(\"MSE\")\n\nplt.plot(train_sizes, train_scores_mean, label=\"Training error\")\nplt.plot(train_sizes, test_scores_mean, label=\"Cross-validation error\")\nplt.legend()\nplt.show()\n\n\n\n\n\ninput_features = ['location.depth', 'location.latitude', 'location.longitude', 'time.epoch', 'impact.gap']\noutput_variables = ['impact.magnitude', 'time.month', 'time.day']\n\nfor input_feat in input_features:\n    plt.figure(figsize=(8, 6))\n\n    for output_var in output_variables:\n        plt.scatter(X_test[input_feat], y_test[output_var], label=f'Actual {output_var}', alpha=0.6)\n        plt.scatter(X_test[input_feat], poly_predictions[:, output_variables.index(output_var)], label=f'Predicted {output_var}', alpha=0.6)\n\n        plt.xlabel(input_feat)\n        plt.ylabel('Output Variables')\n        plt.title(f'Output Variables vs {input_feat}')\n        plt.legend()\n\n    plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfor input_feat in input_features:\n    for output_var in output_variables:\n        plt.figure(figsize=(8, 6))\n        \n        # Plot the actual values\n        plt.scatter(X_test[input_feat], y_test[output_var], label=f'Actual {output_var}', alpha=0.6)\n        \n        # Plot the predicted values with a line\n        sorted_indices = X_test[input_feat].argsort()\n        plt.plot(X_test[input_feat].values[sorted_indices], poly_predictions[:, output_variables.index(output_var)][sorted_indices], \n                 label=f'Predicted {output_var}', color='red', lw=2)\n\n        plt.xlabel(input_feat)\n        plt.ylabel('Output Variables')\n        plt.title(f'Output Variables vs {input_feat}')\n        plt.legend()\n\n        plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsvm_model = MultiOutputRegressor(SVR(kernel='rbf', C=0.1))\n\nsvm_model.fit(X_train, y_train)\n\nsvm_predictions = svm_model.predict(X_test)\nmse = mean_squared_error(y_test, svm_predictions)\nprint(f\"Mean Squared Error with SVM: {mse}\")\n\nMean Squared Error with SVM: 0.30249069882639784\n\n\n\ntrain_sizes1, train_scores1, test_scores1 = learning_curve(svm_model, X, y, cv=3, scoring='neg_mean_squared_error')\n\ntrain_scores_mean1 = -train_scores1.mean(axis=1)\ntest_scores_mean1 = -test_scores1.mean(axis=1)\n\nplt.figure()\nplt.title(\"Learning Curve\")\nplt.xlabel(\"Training examples\")\nplt.ylabel(\"MSE\")\n\nplt.plot(train_sizes1, train_scores_mean1, label=\"Training error\")\nplt.plot(train_sizes1, test_scores_mean1, label=\"Cross-validation error\")\nplt.legend()\nplt.show()\n\n\n\n\n\nfor input_feat in input_features:\n    plt.figure(figsize=(8, 6))\n    \n    for output_var in output_variables:\n        # Get the actual and predicted values for the specific output variable\n        actual_values = y_test[output_var]\n        predicted_values = svm_predictions[:, output_variables.index(output_var)]\n        \n        plt.scatter(X_test[input_feat], actual_values, label=f'Actual {output_var}', alpha=0.6)\n        plt.scatter(X_test[input_feat], predicted_values, label=f'Predicted {output_var}', alpha=0.6)\n    \n    plt.xlabel(input_feat)\n    plt.ylabel('Output Variables')\n    plt.title(f'Output Variables vs {input_feat}')\n    plt.legend()\n    plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfor input_feat in input_features:\n    for output_var in output_variables:\n        plt.figure(figsize=(8, 6))\n        \n        # Plot the actual values\n        plt.scatter(X_test[input_feat], y_test[output_var], label=f'Actual {output_var}', alpha=0.6)\n        \n        # Plot the predicted values with a line\n        sorted_indices = X_test[input_feat].argsort()\n        plt.plot(X_test[input_feat].values[sorted_indices], svm_predictions[:, output_variables.index(output_var)][sorted_indices], \n                 label=f'Predicted {output_var}', color='red', lw=2)\n\n        plt.xlabel(input_feat)\n        plt.ylabel('Output Variables')\n        plt.title(f'Output Variables vs {input_feat}')\n        plt.legend()\n\n        plt.show()"
  },
  {
    "objectID": "posts/disease/index.html",
    "href": "posts/disease/index.html",
    "title": "Disease Analysis",
    "section": "",
    "text": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.decomposition import PCA\nfrom sklearn.mixture import GaussianMixture\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.inspection import DecisionBoundaryDisplay\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import ConfusionMatrixDisplay\nimport scipy.cluster.hierarchy as sch\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\n\ncsv_file_path = \"health.csv\"\ndf = pd.read_csv(csv_file_path)\ndf\n\n\n\n\n\n\n\n\ndisease\nincrease\nloc\nnumber\npopulation\nyear\n\n\n\n\n0\nMEASLES\n334.99\nALABAMA\n8843\n2640000\n1928\n\n\n1\nMEASLES\n200.75\nARIZONA\n847\n422000\n1928\n\n\n2\nMEASLES\n481.77\nARKANSAS\n8899\n1847000\n1928\n\n\n3\nMEASLES\n69.22\nCALIFORNIA\n3698\n5344000\n1928\n\n\n4\nMEASLES\n206.98\nCOLORADO\n2099\n1014000\n1928\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n14260\nPERTUSSIS\n2.06\nVIRGINIA\n171\n8096604\n2011\n\n\n14261\nPERTUSSIS\n10.68\nWASHINGTON\n731\n6830038\n2011\n\n\n14262\nPERTUSSIS\n1.99\nWEST VIRGINIA\n37\n1855364\n2011\n\n\n14263\nPERTUSSIS\n6.20\nWISCONSIN\n351\n5711767\n2011\n\n\n14264\nPERTUSSIS\n1.25\nWYOMING\n7\n568158\n2011\n\n\n\n\n14265 rows × 6 columns\n\n\n\n\nprint(df['disease'].unique())\nprint(df['disease'].value_counts())\n\n['MEASLES' 'POLIO' 'SMALLPOX' 'PERTUSSIS' 'HEPATITIS A' 'RUBELLA' 'MUMPS']\ndisease\nMEASLES        3333\nPERTUSSIS      2716\nHEPATITIS A    2327\nPOLIO          1860\nMUMPS          1576\nRUBELLA        1374\nSMALLPOX       1079\nName: count, dtype: int64\n\n\n\nnumeric_df = df.select_dtypes(include=['number'])\ncols = numeric_df.columns\nscaler = StandardScaler()\nnormalized_data = scaler.fit_transform(numeric_df)\n\npca = PCA(n_components=2)\ndata_pca = pca.fit_transform(normalized_data)\n\nnormalized_df = pd.DataFrame(normalized_data, columns=cols)\nplt.figure(figsize=(8, 4))  \npd.plotting.parallel_coordinates(normalized_df.join(df.disease), class_column='disease', colormap='hsv') \nplt.title('Standardized Parallel Coordinates Plot')\nplt.ylabel('Values')\nplt.show()\n\n\n\n\n\nnum_samples = 1000 \nsample_indices = np.random.choice(data_pca.shape[0], num_samples, replace=False)\nsampled_data = data_pca[sample_indices]\n\nplt.figure(figsize=(8, 6)) \ndendrogram = sch.dendrogram(sch.linkage(sampled_data, method='ward'), orientation='right')  \nplt.title('Dendrogram (Sampled Data)')\nplt.xlabel('Euclidean Distances')\nplt.ylabel('Data Points')\nplt.show()\n\n\n\n\n\nexplained_variance = pca.explained_variance_ratio_\ncumulative_explained_variance = explained_variance.cumsum()\n\ngmm = GaussianMixture(n_components=7, random_state=42)\nclusters = gmm.fit_predict(data_pca)\n\nplt.figure(figsize=(8, 6))\nplt.scatter(data_pca[:, 0], data_pca[:, 1], c=clusters, cmap='viridis', alpha=0.7, s=40)\nplt.xlabel(f'Component 1\\nExplained Variance: {explained_variance[0]:.3f}, Cumulative Explained Variance: {cumulative_explained_variance[0]:.3f}')\nplt.ylabel(f'Component 2\\nExplained Variance: {explained_variance[1]:.3f}, Cumulative Explained Variance: {cumulative_explained_variance[1]:.3f}')\nplt.title('Gaussian Mixture Model Clustering after PCA Dimensionality Reduction')\nplt.colorbar(label='Clusters')\nplt.show()\n\n\n\n\n\nX1 = data_pca \ny1 = df['disease']\nlabel_encoder = LabelEncoder()\ny1 = label_encoder.fit_transform(y1)\nfeature_1, feature_2 = np.meshgrid(\n    np.linspace(X1[:, 0].min(), X1[:, 0].max()),\n    np.linspace(X1[:, 1].min(), X1[:, 1].max())\n)\ngrid = np.vstack([feature_1.ravel(), feature_2.ravel()]).T\ntree = DecisionTreeClassifier().fit(X1, y1)\ny_pred1 = tree.predict(grid)\ny_pred1 = y_pred1.reshape(feature_1.shape)\ndisplay = DecisionBoundaryDisplay(xx0=feature_1, xx1=feature_2, response=y_pred1)\ndisplay.plot()\nplt.scatter(X1[:, 0], X1[:, 1], c=y1, edgecolor=\"k\", s=10)\nplt.show()\n\n\n\n\n\ncluster_data = pd.DataFrame({'Cluster': clusters, 'Class': df['disease']}) \ncluster_summary = cluster_data.groupby('Cluster')['Class'].value_counts().unstack().fillna(0)\nprint(cluster_summary)\n\nClass    HEPATITIS A  MEASLES   MUMPS  PERTUSSIS   POLIO  RUBELLA  SMALLPOX\nCluster                                                                    \n0               11.0    216.0    31.0      360.0  1169.0     14.0     859.0\n1             1658.0   1056.0  1047.0     1285.0   360.0    960.0       0.0\n2                6.0    271.0     5.0        8.0     0.0      2.0       0.0\n3              247.0    194.0   177.0      157.0   158.0    194.0      42.0\n4                0.0    687.0    23.0      121.0     5.0      1.0       0.0\n5               16.0    722.0    70.0      363.0   168.0     41.0     178.0\n6              389.0    187.0   223.0      422.0     0.0    162.0       0.0\n\n\n\ndensities = gmm.score_samples(data_pca)\n\nlower_bound = np.percentile(densities, 0.1)\nanomalies = data_pca[densities &lt; lower_bound]\n\nprint(\"Anomalies:\", anomalies, \"\\n Shape:\", anomalies.shape) \n\nAnomalies: [[10.07872492  0.71333442]\n [14.05229786  5.03523068]\n [12.43006816  6.13229002]\n [13.0640971   1.21331516]\n [13.35301494  6.05062185]\n [13.4855688   4.98454229]\n [18.11348029  9.06984412]\n [16.51090648  5.02577769]\n [13.18315682  7.65367663]\n [13.70015428  6.97071012]\n [14.00925655  6.42533074]\n [11.84210663  1.36010773]\n [10.08348551  0.71877513]\n [10.17446008  7.08024078]\n [-0.37423383  5.14443646]] \n Shape: (15, 2)\n\n\n\nplt.figure(figsize=(8, 6))\nplt.scatter(data_pca[:, 0], data_pca[:, 1], c=clusters, cmap='viridis', alpha=0.7, s=40)\nplt.xlabel(f'Component 1\\nExplained Variance: {explained_variance[0]:.3f}, Cumulative Explained Variance: {cumulative_explained_variance[0]:.3f}')\nplt.ylabel(f'Component 2\\nExplained Variance: {explained_variance[1]:.3f}, Cumulative Explained Variance: {cumulative_explained_variance[1]:.3f}')\nplt.title('Gaussian Mixture Model Clustering after PCA Dimensionality Reduction')\nplt.colorbar(label='Clusters')\n\nplt.scatter(anomalies[:, 0], anomalies[:, 1], c='red', marker='x', s=100, label='Anomalies')\nplt.legend()\nplt.show()\n\n\n\n\n\nlabels = df['disease']\n\nclassifier = DecisionTreeClassifier(random_state=42)\nclassifier.fit(normalized_data, labels)\n\npredicted_labels = classifier.predict(normalized_data)\nconf_matrix = confusion_matrix(labels, predicted_labels)\n\ndisp = ConfusionMatrixDisplay(conf_matrix, display_labels=classifier.classes_)\ndisp.plot(cmap='viridis', values_format='.0f')\nplt.title('Confusion Matrix for Decision Tree Classifier')\nplt.show()"
  },
  {
    "objectID": "posts/dry_beans/index.html",
    "href": "posts/dry_beans/index.html",
    "title": "Dry Beans Anaysis",
    "section": "",
    "text": "This is a post with executable code.\n\nimport pandas as pd\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import accuracy_score, classification_report, roc_curve, auc, roc_auc_score\nimport matplotlib.pyplot as plt\nimport matplotlib\nimport numpy as np\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\nimport scipy.cluster.hierarchy as sch\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import recall_score\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import ConfusionMatrixDisplay\nfrom sklearn.inspection import DecisionBoundaryDisplay\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import label_binarize\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\n\nexcel_file_path = \"DryBeanDataset/Dry_Bean_Dataset.xlsx\"\ndf = pd.read_excel(excel_file_path)\ndf\n\n\n\n\n\n\n\n\nArea\nPerimeter\nMajorAxisLength\nMinorAxisLength\nAspectRation\nEccentricity\nConvexArea\nEquivDiameter\nExtent\nSolidity\nroundness\nCompactness\nShapeFactor1\nShapeFactor2\nShapeFactor3\nShapeFactor4\nClass\n\n\n\n\n0\n28395\n610.291\n208.178117\n173.888747\n1.197191\n0.549812\n28715\n190.141097\n0.763923\n0.988856\n0.958027\n0.913358\n0.007332\n0.003147\n0.834222\n0.998724\nSEKER\n\n\n1\n28734\n638.018\n200.524796\n182.734419\n1.097356\n0.411785\n29172\n191.272750\n0.783968\n0.984986\n0.887034\n0.953861\n0.006979\n0.003564\n0.909851\n0.998430\nSEKER\n\n\n2\n29380\n624.110\n212.826130\n175.931143\n1.209713\n0.562727\n29690\n193.410904\n0.778113\n0.989559\n0.947849\n0.908774\n0.007244\n0.003048\n0.825871\n0.999066\nSEKER\n\n\n3\n30008\n645.884\n210.557999\n182.516516\n1.153638\n0.498616\n30724\n195.467062\n0.782681\n0.976696\n0.903936\n0.928329\n0.007017\n0.003215\n0.861794\n0.994199\nSEKER\n\n\n4\n30140\n620.134\n201.847882\n190.279279\n1.060798\n0.333680\n30417\n195.896503\n0.773098\n0.990893\n0.984877\n0.970516\n0.006697\n0.003665\n0.941900\n0.999166\nSEKER\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n13606\n42097\n759.696\n288.721612\n185.944705\n1.552728\n0.765002\n42508\n231.515799\n0.714574\n0.990331\n0.916603\n0.801865\n0.006858\n0.001749\n0.642988\n0.998385\nDERMASON\n\n\n13607\n42101\n757.499\n281.576392\n190.713136\n1.476439\n0.735702\n42494\n231.526798\n0.799943\n0.990752\n0.922015\n0.822252\n0.006688\n0.001886\n0.676099\n0.998219\nDERMASON\n\n\n13608\n42139\n759.321\n281.539928\n191.187979\n1.472582\n0.734065\n42569\n231.631261\n0.729932\n0.989899\n0.918424\n0.822730\n0.006681\n0.001888\n0.676884\n0.996767\nDERMASON\n\n\n13609\n42147\n763.779\n283.382636\n190.275731\n1.489326\n0.741055\n42667\n231.653248\n0.705389\n0.987813\n0.907906\n0.817457\n0.006724\n0.001852\n0.668237\n0.995222\nDERMASON\n\n\n13610\n42159\n772.237\n295.142741\n182.204716\n1.619841\n0.786693\n42600\n231.686223\n0.788962\n0.989648\n0.888380\n0.784997\n0.007001\n0.001640\n0.616221\n0.998180\nDERMASON\n\n\n\n\n13611 rows × 17 columns\n\n\n\n\nnumeric_df = df.select_dtypes(include=['number'])\ncols = numeric_df.columns\nscaler = StandardScaler()\nnumeric_df = scaler.fit_transform(numeric_df)\npca = PCA(n_components=2)\ndf_pca = pca.fit_transform(numeric_df)\nnormalized_df = pd.DataFrame(numeric_df, columns=cols)\n\nplt.figure(figsize=(23, 6))  \npd.plotting.parallel_coordinates(normalized_df.join(df.Class), class_column='Class', colormap='hsv') \nplt.title('Standardized Parallel Coordinates Plot')\nplt.ylabel('Values')\nplt.show()\n\n\n\n\n\nkmeans = KMeans(n_clusters=7, random_state=42)\ndf['Cluster'] = kmeans.fit_predict(df_pca)\nlabels = kmeans.labels_\n\ncluster_centers = kmeans.cluster_centers_\n\ndistances = []\nfor i, label in enumerate(kmeans.labels_):\n    center = cluster_centers[label]\n    point = df_pca[i]\n    distance = np.linalg.norm(point - center)  # Euclidean distance\n    distances.append(distance)\n\nthreshold = np.percentile(distances, 99)  \nanomalies = df_pca[np.array(distances) &gt; threshold]\n\nplt.figure(figsize=(8, 6))\nplt.scatter(df_pca[:, 0], df_pca[:, 1], c=labels, cmap='viridis', marker='o', alpha=0.6)\nplt.scatter(cluster_centers[:, 0], cluster_centers[:, 1], s=100, c='cyan', marker='o', label='Cluster Centers')\nplt.xlabel(f'Principal Component 1 (Explained Variance: {pca.explained_variance_ratio_[0]:.3f}')\nplt.ylabel(f'Principal Component 2 (Explained Variance: {pca.explained_variance_ratio_[1]:.3f}')\nplt.title('Clustering of Dry Beans using KMeans with 7 clusters')\nplt.scatter(anomalies[:, 0], anomalies[:, 1], c='red', marker='x', s=100, label='Anomalies')\nplt.legend()\nplt.show()\n\n\n\n\n\nX1 = df_pca\ny1 = df['Class']\nlabel_encoder = LabelEncoder()\ny1 = label_encoder.fit_transform(y1)\nfeature_1, feature_2 = np.meshgrid(\n    np.linspace(X1[:, 0].min(), X1[:, 0].max()),\n    np.linspace(X1[:, 1].min(), X1[:, 1].max())\n)\ngrid = np.vstack([feature_1.ravel(), feature_2.ravel()]).T\ntree = DecisionTreeClassifier().fit(X1, y1)\ny_pred1 = tree.predict(grid)\ny_pred1 = y_pred1.reshape(feature_1.shape)\ndisplay = DecisionBoundaryDisplay(xx0=feature_1, xx1=feature_2, response=y_pred1)\ndisplay.plot()\nplt.scatter(X1[:, 0], X1[:, 1], c=y1, edgecolor=\"k\", s=10)\nplt.show()\n\n\n\n\n\ncluster_data = pd.DataFrame({'Cluster': df['Cluster'], 'Class': df['Class']})  \ncluster_summary = cluster_data.groupby('Cluster')['Class'].value_counts().unstack().fillna(0)\nprint(cluster_summary)\n\nClass    BARBUNYA  BOMBAY    CALI  DERMASON   HOROZ   SEKER    SIRA\nCluster                                                            \n0             9.0     0.0     2.0     116.0     0.0  1869.0    29.0\n1            12.0     0.0    23.0      12.0  1814.0     1.0    72.0\n2            98.0     0.0    13.0     457.0    52.0    77.0  2280.0\n3             1.0   520.0     0.0       0.0     0.0     0.0     0.0\n4             0.0     0.0     0.0    2961.0     3.0    77.0   249.0\n5           824.0     2.0   347.0       0.0     0.0     3.0     1.0\n6           378.0     0.0  1245.0       0.0    59.0     0.0     5.0\n\n\n\nX = numeric_df \ny = df['Class']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nclf = DecisionTreeClassifier(max_depth=8, random_state=42)\nclf.fit(X_train, y_train)\n\ny_scores = clf.predict_proba(X_test)\ny_pred = clf.predict(X_test)\n\ncm = confusion_matrix(y_test, y_pred, labels=clf.classes_)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=clf.classes_)\ndisp.plot(cmap='Blues', values_format='d')\nplt.show()\n\n\n\n\n\ny_bin = label_binarize(y_test, classes=clf.classes_)\n\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\n\nfor i in range(len(clf.classes_)):\n    fpr[i], tpr[i], _ = roc_curve(y_bin[:, i], y_scores[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# Plot ROC curves\nplt.figure(figsize=(8, 6))\n\nfor i in range(len(clf.classes_)):\n    plt.plot(fpr[i], tpr[i], label=f'ROC curve (area = {roc_auc[i]:.2f}) for class {clf.classes_[i]}')\n\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic (ROC) Curve for Multiclass Classification')\nplt.legend(loc=\"lower right\")\nplt.show()\n\n\n\n\n\ntrain_sizes, train_scores, test_scores = learning_curve(clf, X_train, y_train, train_sizes=np.linspace(0.1, 1.0, 10), cv=5, scoring='accuracy')\n\ntrain_scores_mean = np.mean(train_scores, axis=1)\ntrain_scores_std = np.std(train_scores, axis=1)\ntest_scores_mean = np.mean(test_scores, axis=1)\ntest_scores_std = np.std(test_scores, axis=1)\n\nplt.figure()\nplt.title(\"Learning Curve\")\nplt.xlabel(\"Training examples\")\nplt.ylabel(\"Accuracy\")\n\nplt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\nplt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n\nplt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\nplt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n\nplt.legend()\nplt.show()\n\n\n\n\n\nfrom IPython.display import Image\nimport pydot\nfrom sklearn.tree import export_graphviz\nimport graphviz\n\ndata=export_graphviz(\n    clf,\n    feature_names=df.drop(columns=['Class', 'Cluster']).columns,\n    class_names=clf.classes_,\n    rounded=True,\n    filled=True,\n    max_depth=4,\n)\n\ngraph = pydot.graph_from_dot_data(data)\nImage(graph[0].create_png())\n\n# graph = graphviz.Source(data)\n# graph.render(\"decision_tree\")\n\n\n\n\n\nroc_auc = roc_auc_score(y_test, y_scores, multi_class='ovo')  \nprint(f'ROC AUC Score: {roc_auc:.2f}')\n\nROC AUC Score: 0.98\n\n\n\nscores = cross_val_score(clf, X, y, cv=5, scoring='accuracy')\nmean_score = scores.mean()\nstd_score = scores.std()\nprint(f'Standard Error Score: {std_score:.2f}')\n\nStandard Error Score: 0.18\n\n\n\n# recall = recall_score(y_test, y_pred, average=None)\nrecall = recall_score(y_test, y_pred, average='macro')\nprint(f'Recall Score: {recall:.2f}')\n\nRecall Score: 0.91\n\n\n\nX_train1, X_test1, y_train1, y_test1 = train_test_split(X, y, test_size=0.2, random_state=42)\n\nclf1 = RandomForestClassifier(n_estimators=20, max_depth=8, random_state=42)\nclf1.fit(X_train1, y_train1)\n\ny_scores1 = clf1.predict_proba(X_test1)\n\nfpr1 = dict()\ntpr1 = dict()\nroc_auc1 = dict()\n\nfor i in range(len(clf1.classes_)):\n    fpr1[i], tpr1[i], _ = roc_curve((y_test1 == clf1.classes_[i]).astype(int), y_scores1[:, i])\n    roc_auc1[i] = auc(fpr1[i], tpr1[i])\n\nplt.figure(figsize=(8, 6))\n\nfor i in range(len(clf1.classes_)):\n    plt.plot(fpr1[i], tpr1[i], label=f'ROC curve (area = {roc_auc1[i]:.2f}) for class {clf1.classes_[i]}')\n\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic (ROC) Curve for Multiclass Classification')\nplt.legend(loc=\"lower right\")\nplt.show()\n\n\n\n\n\ntrain_sizes1, train_scores1, test_scores1 = learning_curve(clf1, X_train1, y_train1, train_sizes=np.linspace(0.1, 1.0, 10), cv=5, scoring='accuracy')\n\ntrain_scores_mean1 = np.mean(train_scores1, axis=1)\ntrain_scores_std1 = np.std(train_scores1, axis=1)\ntest_scores_mean1 = np.mean(test_scores1, axis=1)\ntest_scores_std1 = np.std(test_scores1, axis=1)\n\nplt.figure()\nplt.title(\"Learning Curve\")\nplt.xlabel(\"Training examples\")\nplt.ylabel(\"Accuracy\")\n\nplt.plot(train_sizes1, train_scores_mean1, 'o-', color=\"r\", label=\"Training score\")\nplt.plot(train_sizes1, test_scores_mean1, 'o-', color=\"g\", label=\"Cross-validation score\")\n\nplt.fill_between(train_sizes1, train_scores_mean1 - train_scores_std1, train_scores_mean1 + train_scores_std1, alpha=0.1, color=\"r\")\nplt.fill_between(train_sizes1, test_scores_mean1 - test_scores_std1, test_scores_mean1 + test_scores_std1, alpha=0.1, color=\"g\")\n\nplt.legend()\nplt.show()\n\n\n\n\n\ny_pred1 = clf1.predict(X_test1)\ncm1 = confusion_matrix(y_test1, y_pred1, labels=clf1.classes_)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm1, display_labels=clf1.classes_)\ndisp.plot(cmap='Purples', values_format='d')\nplt.show()\n\n\n\n\n\nscores = cross_val_score(clf, X, y, cv=5, scoring='accuracy')\nmean_score = scores.mean()\nstd_score = scores.std()\nprint(f'Standard Error Score: {std_score:.2f}')\n\nStandard Error Score: 0.18\n\n\n\nrecall = recall_score(y_test, y_pred, average='macro')\nprint(f'Recall Score: {recall:.2f}')\n\nRecall Score: 0.91\n\n\n\nroc_auc = roc_auc_score(y_test, y_scores, multi_class='ovo')  \nprint(f'ROC AUC Score: {roc_auc:.2f}')\n\nROC AUC Score: 0.98\n\n\n\nX_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, test_size=0.2, random_state=42)\n\nclf2 = SVC(probability=True, C=0.2, random_state=42)\nclf2.fit(X_train2, y_train2)\n\ny_scores2 = clf2.predict_proba(X_test2)\n\nfpr2 = dict()\ntpr2 = dict()\nroc_auc2 = dict()\n\nfor i in range(len(clf2.classes_)):\n    fpr2[i], tpr2[i], _ = roc_curve((y_test2 == clf2.classes_[i]).astype(int), y_scores2[:, i])\n    roc_auc2[i] = auc(fpr2[i], tpr2[i])\n\nplt.figure(figsize=(8, 6))\n\nfor i in range(len(clf2.classes_)):\n    plt.plot(fpr2[i], tpr2[i], label=f'ROC curve (area = {roc_auc2[i]:.2f}) for class {clf2.classes_[i]}')\n\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic (ROC) Curve for Multiclass Classification')\nplt.legend(loc=\"lower right\")\nplt.show()"
  }
]